"""
ThreatGuard Pro - Enhanced Vulnerability Management API
New endpoints for Terraform integration, wave management, and enhanced vulnerability tracking
"""

from flask import Blueprint, request, jsonify, g
from datetime import datetime, timedelta
from pathlib import Path
import uuid
import logging
import time
import functools
import os
import json
from typing import Dict, List, Any, Optional, Callable
import re

from database import db_manager
# from terraform_generator import terraform_generator
# from wave_manager import wave_manager

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create blueprint for enhanced vulnerability management
vulnerability_api = Blueprint('vulnerability_api', __name__)

# ============================================================================
# Robustness Enhancements
# ============================================================================

def load_sample_vulnerabilities():
    """Load sample vulnerability data from JSON file"""
    try:
        json_file_path = os.path.join(os.path.dirname(__file__), 'sample_vulnerabilities.json')
        if not os.path.exists(json_file_path):
            logger.warning(f"Sample vulnerabilities file not found: {json_file_path}")
            return []
        
        with open(json_file_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            return data.get('vulnerabilities', [])
    except Exception as e:
        logger.error(f"Error loading sample vulnerabilities: {e}")
        return []

# Load sample data at module level
SAMPLE_VULNERABILITIES = load_sample_vulnerabilities()

def load_scan_results():
    """Load scan results from scan_history.json and convert to vulnerability format"""
    try:
        scan_history_file = os.path.join(os.path.dirname(__file__), 'threatguard_data', 'scan_history.json')
        if not os.path.exists(scan_history_file):
            logger.warning(f"Scan history file not found: {scan_history_file}")
            return []
        
        with open(scan_history_file, 'r', encoding='utf-8') as file:
            scan_history = json.load(file)
        
        vulnerabilities = []
        for scan in scan_history:
            if 'issues' in scan and scan['issues']:
                for issue in scan['issues']:
                    # Convert scan issue to vulnerability format
                    vulnerability = {
                        'id': issue.get('id', str(uuid.uuid4())),
                        'title': issue.get('message', 'Security Issue'),
                        'description': issue.get('suggested_fix', ''),
                        'severity': issue.get('severity', 'MEDIUM_RISK'),
                        'type': issue.get('type', 'SECURITY_ISSUE'),
                        'status': issue.get('status', 'ACTIVE_THREAT'),
                        'file_path': issue.get('file_path', ''),
                        'line_number': issue.get('line_number', 0),
                        'code_snippet': issue.get('code_snippet', ''),
                        'remediation_action': issue.get('suggested_fix', ''),
                        'effort_minutes': issue.get('effort', 0),
                        'ait_tag': issue.get('ait_tag', ''),
                        'spk_tag': issue.get('spk_tag', ''),
                        'repo_name': issue.get('repo_name', ''),
                        'scan_id': issue.get('scan_id', ''),
                        'creation_date': issue.get('creation_date', ''),
                        'update_date': issue.get('update_date', ''),
                        'threat_level': issue.get('threat_level', 'UNKNOWN'),
                        'debt_category': issue.get('debt_category', ''),
                        'business_impact': issue.get('business_impact', ''),
                        'compliance_impact': issue.get('compliance_impact', ''),
                        'security_domain': issue.get('security_domain', ''),
                        'source': 'scan_result'
                    }
                    vulnerabilities.append(vulnerability)
        
        logger.info(f"Loaded {len(vulnerabilities)} vulnerabilities from scan results")
        return vulnerabilities
        
    except Exception as e:
        logger.error(f"Error loading scan results: {e}")
        return []

# Load scan results at module level
SCAN_RESULT_VULNERABILITIES = load_scan_results()

def refresh_scan_results():
    """Refresh scan results from scan_history.json"""
    global SCAN_RESULT_VULNERABILITIES
    try:
        SCAN_RESULT_VULNERABILITIES = load_scan_results()
        logger.info(f"Refreshed scan results: {len(SCAN_RESULT_VULNERABILITIES)} vulnerabilities")
        return True
    except Exception as e:
        logger.error(f"Error refreshing scan results: {e}")
        return False

# Rate limiting configuration
RATE_LIMIT_WINDOW = 60  # seconds
RATE_LIMIT_MAX_REQUESTS = 100  # requests per window
rate_limit_store = {}

def rate_limit(f: Callable) -> Callable:
    """Rate limiting decorator"""
    @functools.wraps(f)
    def decorated_function(*args, **kwargs):
        global rate_limit_store
        client_ip = request.remote_addr
        current_time = time.time()
        
        # Clean old entries
        rate_limit_store = {ip: (count, timestamp) for ip, (count, timestamp) in rate_limit_store.items() 
                           if current_time - timestamp < RATE_LIMIT_WINDOW}
        
        if client_ip in rate_limit_store:
            count, timestamp = rate_limit_store[client_ip]
            if current_time - timestamp < RATE_LIMIT_WINDOW and count >= RATE_LIMIT_MAX_REQUESTS:
                return jsonify({
                    'success': False,
                    'error': 'Rate limit exceeded. Please try again later.',
                    'retry_after': RATE_LIMIT_WINDOW - (current_time - timestamp)
                }), 429
            
            rate_limit_store[client_ip] = (count + 1, timestamp)
        else:
            rate_limit_store[client_ip] = (1, current_time)
        
        return f(*args, **kwargs)
    return decorated_function

def validate_input(data: Dict, required_fields: List[str], optional_fields: List[str] = None) -> tuple[bool, str, Dict]:
    """Validate input data"""
    try:
        # Check required fields
        for field in required_fields:
            if field not in data or data[field] is None:
                return False, f"Missing required field: {field}", {}
        
        # Validate field types and values
        validated_data = {}
        for field, value in data.items():
            if field in required_fields or (optional_fields and field in optional_fields):
                # Type validation
                if field == 'severity' and value not in ['CRITICAL_BOMB', 'HIGH_RISK', 'MEDIUM_RISK', 'LOW_RISK', 'SUSPICIOUS']:
                    return False, f"Invalid severity value: {value}", {}
                elif field == 'type' and not re.match(r'^[A-Z_]+$', str(value)):
                    return False, f"Invalid type format: {value}", {}
                elif field == 'priority' and value not in ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']:
                    return False, f"Invalid priority value: {value}", {}
                elif field == 'business_impact' and value not in ['Critical', 'High', 'Medium', 'Low']:
                    return False, f"Invalid business impact value: {value}", {}
                
                validated_data[field] = value
        
        return True, "", validated_data
        
    except Exception as e:
        return False, f"Validation error: {str(e)}", {}

def log_request(f: Callable) -> Callable:
    """Request logging decorator"""
    @functools.wraps(f)
    def decorated_function(*args, **kwargs):
        start_time = time.time()
        client_ip = request.remote_addr
        user_agent = request.headers.get('User-Agent', 'Unknown')
        
        logger.info(f"API Request: {request.method} {request.path} from {client_ip} - User-Agent: {user_agent}")
        
        try:
            result = f(*args, **kwargs)
            duration = time.time() - start_time
            logger.info(f"API Response: {request.method} {request.path} completed in {duration:.3f}s")
            return result
        except Exception as e:
            duration = time.time() - start_time
            logger.error(f"API Error: {request.method} {request.path} failed after {duration:.3f}s - Error: {str(e)}")
            raise
        
    return decorated_function

def retry_on_failure(max_retries: int = 3, delay: float = 1.0):
    """Retry decorator for database operations"""
    def decorator(f: Callable) -> Callable:
        @functools.wraps(f)
        def decorated_function(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return f(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        logger.warning(f"Attempt {attempt + 1} failed for {f.__name__}: {e}. Retrying in {delay}s...")
                        time.sleep(delay)
                        delay *= 2  # Exponential backoff
            
            logger.error(f"All {max_retries} attempts failed for {f.__name__}: {last_exception}")
            raise last_exception
        
        return decorated_function
    return decorator

# ============================================================================
# Enhanced Vulnerability Management Endpoints
# ============================================================================

@vulnerability_api.route('/api/v1/vulnerabilities', methods=['GET'])
@rate_limit
@log_request
def get_enhanced_vulnerabilities():
    """Get vulnerabilities with enhanced filtering and metadata"""
    try:
        # Get query parameters with validation
        severity = request.args.get('severity')
        vuln_type = request.args.get('type')
        status = request.args.get('status')
        debt_category = request.args.get('debt_category')
        wave_id = request.args.get('wave_id')
        page = request.args.get('page', 1, type=int)
        per_page = min(request.args.get('per_page', 50, type=int), 100)  # Cap at 100
        
        # Validate pagination parameters
        if page < 1 or per_page < 1:
            return jsonify({
                'success': False,
                'error': 'Invalid pagination parameters'
            }), 400
        
        # Build filters
        filters = {}
        if severity:
            if severity not in ['CRITICAL_BOMB', 'HIGH_RISK', 'MEDIUM_RISK', 'LOW_RISK', 'SUSPICIOUS']:
                return jsonify({
                    'success': False,
                    'error': f'Invalid severity value: {severity}'
                }), 400
            filters['severity'] = severity
        
        if vuln_type:
            if not re.match(r'^[A-Z_]+$', vuln_type):
                return jsonify({
                    'success': False,
                    'error': f'Invalid type format: {vuln_type}'
                }), 400
            filters['type'] = vuln_type
        
        if status:
            if status not in ['ACTIVE_THREAT', 'NEUTRALIZED', 'UNDER_REVIEW', 'FALSE_POSITIVE', 'RESOLVED']:
                return jsonify({
                    'success': False,
                    'error': f'Invalid status value: {status}'
                }), 400
            filters['status'] = status
        
        if debt_category:
            filters['debt_category'] = debt_category
        
        # Get vulnerabilities from sample data and scan results
        vulnerabilities = SAMPLE_VULNERABILITIES.copy() + load_scan_results()
        
        # Apply filters
        if filters:
            filtered_vulns = []
            for vuln in vulnerabilities:
                include_vuln = True
                
                if 'severity' in filters and vuln.get('severity') != filters['severity']:
                    include_vuln = False
                
                if 'type' in filters and vuln.get('type') != filters['type']:
                    include_vuln = False
                
                if 'status' in filters and vuln.get('status') != filters['status']:
                    include_vuln = False
                
                if 'debt_category' in filters and vuln.get('debt_category') != filters['debt_category']:
                    include_vuln = False
                
                if include_vuln:
                    filtered_vulns.append(vuln)
            
            vulnerabilities = filtered_vulns
        
        # Add wave assignment information if requested
        if wave_id:
            if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', wave_id):
                return jsonify({
                    'success': False,
                    'error': 'Invalid wave ID format'
                }), 400
            
            # Filter vulnerabilities by wave_id (using wave_id from wave_assignment)
            wave_vulns = [vuln for vuln in vulnerabilities 
                         if vuln.get('wave_assignment', {}).get('wave_id') == wave_id]
            vulnerabilities = wave_vulns
        
        # Add enhanced metadata
        for vuln in vulnerabilities:
            vuln['risk_score'] = _calculate_risk_score(vuln)
            vuln['remediation_priority'] = _calculate_remediation_priority(vuln)
            vuln['cost_impact'] = _estimate_cost_impact(vuln)
            vuln['fte_requirement'] = _estimate_fte_requirement(vuln)
        
        # Pagination
        total_count = len(vulnerabilities)
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        paginated_vulns = vulnerabilities[start_idx:end_idx]
        
        return jsonify({
            'success': True,
            'vulnerabilities': paginated_vulns,
            'total_count': total_count,
            'page': page,
            'per_page': per_page,
            'total_pages': (total_count + per_page - 1) // per_page,
            'filters_applied': filters,
            'has_next': end_idx < total_count,
            'has_prev': page > 1
        })
        
    except Exception as e:
        logger.error(f"Failed to get enhanced vulnerabilities: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'VULN_FETCH_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/vulnerabilities/refresh-scan-results', methods=['POST'])
@rate_limit
@log_request
def refresh_vulnerability_scan_results():
    """Refresh scan results from scan_history.json"""
    try:
        success = refresh_scan_results()
        
        if success:
            return jsonify({
                'success': True,
                'message': f'Successfully refreshed scan results. {len(SCAN_RESULT_VULNERABILITIES)} vulnerabilities loaded.',
                'vulnerability_count': len(SCAN_RESULT_VULNERABILITIES)
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to refresh scan results'
            }), 500
            
    except Exception as e:
        logger.error(f"Failed to refresh scan results: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'REFRESH_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/vulnerabilities/<vulnerability_id>', methods=['GET'])
@rate_limit
@log_request
def get_vulnerability_details(vulnerability_id):
    """Get detailed information about a specific vulnerability"""
    try:
        # Validate vulnerability ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', vulnerability_id):
            return jsonify({
                'success': False,
                'error': 'Invalid vulnerability ID format'
            }), 400
        
        # Get vulnerability details with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_vuln():
            return db_manager.get_vulnerabilities({'id': vulnerability_id})
        
        vulnerabilities = get_vuln()
        if not vulnerabilities:
            return jsonify({
                'success': False,
                'error': 'Vulnerability not found',
                'error_code': 'VULN_NOT_FOUND'
            }), 404
        
        vulnerability = vulnerabilities[0] if isinstance(vulnerabilities, list) else vulnerabilities
        
        # Add enhanced information
        vulnerability['risk_score'] = _calculate_risk_score(vulnerability)
        vulnerability['remediation_priority'] = _calculate_remediation_priority(vulnerability)
        vulnerability['cost_impact'] = _estimate_cost_impact(vulnerability)
        vulnerability['fte_requirement'] = _estimate_fte_requirement(vulnerability)
        
        # Get wave assignment if any
        wave_assignments = [a for a in wave_manager.assignments if a.vulnerability_id == vulnerability_id]
        if wave_assignments:
            assignment = wave_assignments[0]
            vulnerability['wave_assignment'] = {
                'wave_id': assignment.wave_id,
                'status': assignment.status,
                'assigned_date': assignment.assigned_date,
                'estimated_effort_hours': assignment.estimated_effort_hours,
                'actual_effort_hours': assignment.actual_effort_hours,
                'notes': assignment.notes
            }
        
        # Get remediation history
        vulnerability['remediation_history'] = _get_remediation_history(vulnerability_id)
        
        return jsonify({
            'success': True,
            'vulnerability': vulnerability
        })
        
    except Exception as e:
        logger.error(f"Failed to get vulnerability details: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'VULN_DETAILS_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/vulnerabilities/<vulnerability_id>/wave', methods=['POST'])
@rate_limit
@log_request
def assign_vulnerability_to_wave(vulnerability_id):
    """Assign a vulnerability to a remediation wave"""
    try:
        # Validate vulnerability ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', vulnerability_id):
            return jsonify({
                'success': False,
                'error': 'Invalid vulnerability ID format'
            }), 400
        
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        is_valid, error_msg, validated_data = validate_input(
            data, 
            ['wave_id'], 
            ['assigned_by', 'estimated_effort_hours']
        )
        
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg
            }), 400
        
        wave_id = validated_data['wave_id']
        assigned_by = validated_data.get('assigned_by', 'system')
        estimated_effort_hours = validated_data.get('estimated_effort_hours', 0.0)
        
        # Validate wave ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', wave_id):
            return jsonify({
                'success': False,
                'error': 'Invalid wave ID format'
            }), 400
        
        # Validate effort hours
        if estimated_effort_hours < 0 or estimated_effort_hours > 1000:
            return jsonify({
                'success': False,
                'error': 'Estimated effort hours must be between 0 and 1000'
            }), 400
        
        # Assign vulnerability to wave with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def assign_vuln():
            return wave_manager.assign_vulnerability_to_wave(
                vulnerability_id, wave_id, assigned_by, estimated_effort_hours
            )
        
        success = assign_vuln()
        
        if success:
            return jsonify({
                'success': True,
                'message': f'Vulnerability {vulnerability_id} assigned to wave {wave_id}',
                'assignment_id': f"{vulnerability_id}_{wave_id}"
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to assign vulnerability to wave',
                'error_code': 'ASSIGNMENT_FAILED'
            }), 400
        
    except Exception as e:
        logger.error(f"Failed to assign vulnerability to wave: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'ASSIGNMENT_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/vulnerabilities/<vulnerability_id>/status', methods=['PUT'])
@rate_limit
@log_request
def update_vulnerability_status(vulnerability_id):
    """Update vulnerability status (ACTIVE/NEUTRALIZED)"""
    try:
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        if not data or 'status' not in data:
            return jsonify({
                'success': False,
                'error': 'Status field is required'
            }), 400
        
        new_status = data['status']
        if new_status not in ['ACTIVE', 'NEUTRALIZED']:
            return jsonify({
                'success': False,
                'error': 'Status must be either ACTIVE or NEUTRALIZED'
            }), 400
        
        # Load sample vulnerabilities to find and update the vulnerability
        vulnerabilities_file = Path("sample_vulnerabilities.json")
        if not vulnerabilities_file.exists():
            return jsonify({
                'success': False,
                'error': 'Vulnerabilities data not found'
            }), 404
        
        with open(vulnerabilities_file, 'r') as f:
            data = json.load(f)
            vulnerabilities = data.get('vulnerabilities', [])
        
        # Find the vulnerability and update its status
        vulnerability_found = False
        for vuln in vulnerabilities:
            if vuln.get('id') == vulnerability_id:
                # Add or update the status field
                vuln['status'] = new_status
                vulnerability_found = True
                break
        
        if not vulnerability_found:
            return jsonify({
                'success': False,
                'error': 'Vulnerability not found'
            }), 404
        
        # Save the updated data back to file
        with open(vulnerabilities_file, 'w') as f:
            json.dump({'vulnerabilities': vulnerabilities}, f, indent=2)
        
        return jsonify({
            'success': True,
            'message': f'Vulnerability {vulnerability_id} status updated to {new_status}',
            'vulnerability_id': vulnerability_id,
            'new_status': new_status
        })
        
    except Exception as e:
        logger.error(f"Failed to update vulnerability status: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'STATUS_UPDATE_ERROR'
        }), 500

# ============================================================================
# Terraform Integration Endpoints
# ============================================================================

@vulnerability_api.route('/api/v1/terraform/generate', methods=['POST'])
@rate_limit
@log_request
def generate_terraform_script():
    """Generate Terraform script for vulnerability remediation"""
    try:
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        is_valid, error_msg, validated_data = validate_input(
            data, 
            ['vulnerabilityIds'], 
            ['useAICopilot', 'targetEnvironment']
        )
        
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg
            }), 400
        
        vulnerability_ids = validated_data['vulnerabilityIds']
        use_ai_copilot = validated_data.get('useAICopilot', False)
        target_environment = validated_data.get('targetEnvironment', 'dev')
        
        # Validate vulnerability IDs
        if not isinstance(vulnerability_ids, list) or len(vulnerability_ids) == 0:
            return jsonify({
                'success': False,
                'error': 'vulnerabilityIds must be a non-empty list'
            }), 400
        
        if len(vulnerability_ids) > 50:  # Limit batch size
            return jsonify({
                'success': False,
                'error': 'Maximum 50 vulnerabilities can be processed in one request'
            }), 400
        
        # Validate each vulnerability ID format
        for vuln_id in vulnerability_ids:
            if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', vuln_id):
                return jsonify({
                    'success': False,
                    'error': f'Invalid vulnerability ID format: {vuln_id}'
                }), 400
        
        # Validate target environment
        if target_environment not in ['dev', 'staging', 'prod', 'test']:
            return jsonify({
                'success': False,
                'error': f'Invalid target environment: {target_environment}'
            }), 400
        
        generated_scripts = []
        
        for vuln_id in vulnerability_ids:
            try:
                # Get vulnerability details with retry
                @retry_on_failure(max_retries=3, delay=0.5)
                def get_vuln():
                    return db_manager.get_vulnerabilities({'id': vuln_id})
                
                vulnerabilities = get_vuln()
                if not vulnerabilities:
                    generated_scripts.append({
                        'vulnerability_id': vuln_id,
                        'script_id': None,
                        'status': 'failed',
                        'error': 'Vulnerability not found'
                    })
                    continue
                
                vulnerability = vulnerabilities[0] if isinstance(vulnerabilities, list) else vulnerabilities
                
                # Generate Terraform script with retry
                @retry_on_failure(max_retries=2, delay=1.0)
                def generate_script():
                    return terraform_generator.generate_terraform_script(vulnerability)
                
                script_id = generate_script()
                if script_id:
                    generated_scripts.append({
                        'vulnerability_id': vuln_id,
                        'script_id': script_id,
                        'status': 'generated'
                    })
                else:
                    generated_scripts.append({
                        'vulnerability_id': vuln_id,
                        'script_id': None,
                        'status': 'failed',
                        'error': 'Script generation failed'
                    })
                    
            except Exception as e:
                logger.error(f"Failed to process vulnerability {vuln_id}: {e}")
                generated_scripts.append({
                    'vulnerability_id': vuln_id,
                    'script_id': None,
                    'status': 'failed',
                    'error': str(e)
                })
        
        return jsonify({
            'success': True,
            'generated_scripts': generated_scripts,
            'total_requested': len(vulnerability_ids),
            'successfully_generated': len([s for s in generated_scripts if s['status'] == 'generated']),
            'failed': len([s for s in generated_scripts if s['status'] == 'failed'])
        })
        
    except Exception as e:
        logger.error(f"Failed to generate Terraform script: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'TERRAFORM_GENERATION_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/terraform/execute/<script_id>', methods=['POST'])
@rate_limit
@log_request
def execute_terraform_script(script_id):
    """Execute Terraform script for vulnerability remediation"""
    try:
        # Validate script ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', script_id):
            return jsonify({
                'success': False,
                'error': 'Invalid script ID format'
            }), 400
        
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        is_valid, error_msg, validated_data = validate_input(
            data, 
            [], 
            ['environment', 'dryRun', 'autoRollback']
        )
        
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg
            }), 400
        
        environment = validated_data.get('environment', 'dev')
        dry_run = validated_data.get('dryRun', True)
        auto_rollback = validated_data.get('autoRollback', False)
        
        # Validate environment
        if environment not in ['dev', 'staging', 'prod', 'test']:
            return jsonify({
                'success': False,
                'error': f'Invalid environment: {environment}'
            }), 400
        
        # Execute Terraform script with retry
        @retry_on_failure(max_retries=2, delay=2.0)
        def execute_script():
            return terraform_generator.execute_script(script_id, environment, dry_run)
        
        result = execute_script()
        
        if result['success']:
            return jsonify({
                'success': True,
                'script_id': script_id,
                'environment': environment,
                'dry_run': dry_run,
                'result': result
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('error', 'Unknown error'),
                'script_id': script_id,
                'error_code': 'TERRAFORM_EXECUTION_FAILED'
            }), 400
        
    except Exception as e:
        logger.error(f"Failed to execute Terraform script: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'TERRAFORM_EXECUTION_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/terraform/validate/<script_id>', methods=['POST'])
@rate_limit
@log_request
def validate_terraform_script(script_id):
    """Validate Terraform script"""
    try:
        # Validate script ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', script_id):
            return jsonify({
                'success': False,
                'error': 'Invalid script ID format'
            }), 400
        
        # Validate script with retry
        @retry_on_failure(max_retries=2, delay=1.0)
        def validate_script():
            script_path = terraform_generator.workspace_path / f"{script_id}.tf"
            return terraform_generator.validate_script(str(script_path))
        
        is_valid, message = validate_script()
        
        return jsonify({
            'success': True,
            'script_id': script_id,
            'is_valid': is_valid,
            'message': message
        })
        
    except Exception as e:
        logger.error(f"Failed to validate Terraform script: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'TERRAFORM_VALIDATION_ERROR'
        }), 500

# ============================================================================
# Wave Management Endpoints
# ============================================================================

@vulnerability_api.route('/api/v1/waves', methods=['GET'])
@rate_limit
@log_request
def get_wave_plans():
    """Get all wave plans"""
    try:
        # Get waves with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_waves():
            return [asdict(wave) for wave in wave_manager.waves]
        
        waves = get_waves()
        
        return jsonify({
            'success': True,
            'waves': waves,
            'total_count': len(waves)
        })
        
    except Exception as e:
        logger.error(f"Failed to get wave plans: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_FETCH_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/waves', methods=['POST'])
@rate_limit
@log_request
def create_wave_plan():
    """Create a new wave plan"""
    try:
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        is_valid, error_msg, validated_data = validate_input(
            data, 
            ['name', 'description', 'target_start_date', 'target_completion_date', 'priority', 'business_impact', 'team_owner'], 
            ['budget_allocation', 'fte_requirement', 'estimated_effort_hours']
        )
        
        if not is_valid:
            return jsonify({
                'success': False,
                'error': error_msg
            }), 400
        
        # Validate dates
        try:
            start_date = datetime.fromisoformat(validated_data['target_start_date'])
            completion_date = datetime.fromisoformat(validated_data['target_completion_date'])
            
            if start_date >= completion_date:
                return jsonify({
                    'success': False,
                    'error': 'Target start date must be before completion date'
                }), 400
            
            if start_date < datetime.now():
                return jsonify({
                    'success': False,
                    'error': 'Target start date cannot be in the past'
                }), 400
                
        except ValueError:
            return jsonify({
                'success': False,
                'error': 'Invalid date format. Use ISO format (YYYY-MM-DDTHH:MM:SS)'
            }), 400
        
        # Validate numeric fields
        budget = validated_data.get('budget_allocation', 0.0)
        fte = validated_data.get('fte_requirement', 0.0)
        effort = validated_data.get('estimated_effort_hours', 0.0)
        
        if budget < 0 or fte < 0 or effort < 0:
            return jsonify({
                'success': False,
                'error': 'Budget, FTE, and effort values must be non-negative'
            }), 400
        
        # Create wave with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def create_wave():
            return wave_manager.create_wave(validated_data)
        
        wave_id = create_wave()
        
        if wave_id:
            return jsonify({
                'success': True,
                'wave_id': wave_id,
                'message': 'Wave plan created successfully'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to create wave plan',
                'error_code': 'WAVE_CREATION_FAILED'
            }), 400
        
    except Exception as e:
        logger.error(f"Failed to create wave plan: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_CREATION_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/waves/<wave_id>', methods=['GET'])
@rate_limit
@log_request
def get_wave_details(wave_id):
    """Get detailed information about a specific wave"""
    try:
        # Validate wave ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', wave_id):
            return jsonify({
                'success': False,
                'error': 'Invalid wave ID format'
            }), 400
        
        # Get wave progress with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_progress():
            return wave_manager.get_wave_progress(wave_id)
        
        progress = get_progress()
        if not progress:
            return jsonify({
                'success': False,
                'error': 'Wave not found',
                'error_code': 'WAVE_NOT_FOUND'
            }), 404
        
        # Get vulnerabilities in this wave with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_vulns():
            return wave_manager.get_vulnerabilities_by_wave(wave_id)
        
        vulnerabilities = get_vulns()
        
        return jsonify({
            'success': True,
            'wave_progress': progress,
            'vulnerabilities': vulnerabilities
        })
        
    except Exception as e:
        logger.error(f"Failed to get wave details: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_DETAILS_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/waves/<wave_id>', methods=['PUT'])
@rate_limit
@log_request
def update_wave_plan(wave_id):
    """Update a wave plan"""
    try:
        # Validate wave ID format
        if not re.match(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', wave_id):
            return jsonify({
                'success': False,
                'error': 'Invalid wave ID format'
            }), 400
        
        # Validate request data
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Request must be JSON'
            }), 400
        
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': 'No update data provided'
            }), 400
        
        # Validate updateable fields
        allowed_fields = ['name', 'description', 'target_start_date', 'target_completion_date', 
                         'status', 'priority', 'business_impact', 'team_owner', 
                         'budget_allocation', 'fte_requirement', 'estimated_effort_hours']
        
        invalid_fields = [field for field in data.keys() if field not in allowed_fields]
        if invalid_fields:
            return jsonify({
                'success': False,
                'error': f'Invalid fields for update: {", ".join(invalid_fields)}'
            }), 400
        
        # Update wave with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def update_wave():
            return wave_manager.update_wave(wave_id, data)
        
        success = update_wave()
        
        if success:
            return jsonify({
                'success': True,
                'message': f'Wave {wave_id} updated successfully'
            })
        else:
            return jsonify({
                'success': False,
                'error': 'Failed to update wave plan',
                'error_code': 'WAVE_UPDATE_FAILED'
            }), 400
        
    except Exception as e:
        logger.error(f"Failed to update wave plan: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_UPDATE_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/waves/progress', methods=['GET'])
@rate_limit
@log_request
def get_all_waves_progress():
    """Get progress for all waves"""
    try:
        # Get progress with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_progress():
            return wave_manager.get_all_waves_progress()
        
        progress = get_progress()
        
        return jsonify({
            'success': True,
            'waves_progress': progress
        })
        
    except Exception as e:
        logger.error(f"Failed to get waves progress: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_PROGRESS_ERROR'
        }), 500

@vulnerability_api.route('/api/v1/waves/recommendations', methods=['GET'])
@rate_limit
@log_request
def get_wave_recommendations():
    """Get recommendations for wave planning"""
    try:
        # Get recommendations with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_recommendations():
            return wave_manager.get_wave_recommendations()
        
        recommendations = get_recommendations()
        
        return jsonify({
            'success': True,
            'recommendations': recommendations
        })
        
    except Exception as e:
        logger.error(f"Failed to get wave recommendations: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'WAVE_RECOMMENDATIONS_ERROR'
        }), 500

# ============================================================================
# Enhanced Metrics and Analytics Endpoints
# ============================================================================

@vulnerability_api.route('/api/v1/metrics/vulnerability-summary', methods=['GET'])
@rate_limit
@log_request
def get_vulnerability_summary():
    """Get comprehensive vulnerability summary with enhanced metrics"""
    try:
        # Get all vulnerabilities with retry
        @retry_on_failure(max_retries=3, delay=0.5)
        def get_vulns():
            return db_manager.get_vulnerabilities()
        
        vulnerabilities = get_vulns()
        
        # Calculate enhanced metrics
        summary = {
            'total_vulnerabilities': len(vulnerabilities),
            'by_severity': {},
            'by_type': {},
            'by_status': {},
            'by_debt_category': {},
            'risk_distribution': {},
            'cost_analysis': {
                'total_estimated_cost': 0,
                'total_fte_requirement': 0,
                'by_severity': {},
                'by_type': {}
            },
            'remediation_timeline': {
                'critical_issues': 0,
                'high_priority': 0,
                'medium_priority': 0,
                'low_priority': 0
            }
        }
        
        # Process vulnerabilities
        for vuln in vulnerabilities:
            severity = vuln.get('severity', 'UNKNOWN')
            vuln_type = vuln.get('type', 'UNKNOWN')
            status = vuln.get('status', 'UNKNOWN')
            debt_category = vuln.get('debt_category', 'UNKNOWN')
            
            # Count by category
            summary['by_severity'][severity] = summary['by_severity'].get(severity, 0) + 1
            summary['by_type'][vuln_type] = summary['by_type'].get(vuln_type, 0) + 1
            summary['by_status'][status] = summary['by_status'].get(status, 0) + 1
            summary['by_debt_category'][debt_category] = summary['by_debt_category'].get(debt_category, 0) + 1
            
            # Calculate risk score
            risk_score = _calculate_risk_score(vuln)
            risk_level = _get_risk_level(risk_score)
            summary['risk_distribution'][risk_level] = summary['risk_distribution'].get(risk_level, 0) + 1
            
            # Calculate cost impact
            cost_impact = _estimate_cost_impact(vuln)
            fte_requirement = _estimate_fte_requirement(vuln)
            
            summary['cost_analysis']['total_estimated_cost'] += cost_impact
            summary['cost_analysis']['total_fte_requirement'] += fte_requirement
            
            # Add to severity-based cost analysis
            if severity not in summary['cost_analysis']['by_severity']:
                summary['cost_analysis']['by_severity'][severity] = {'cost': 0, 'fte': 0}
            summary['cost_analysis']['by_severity'][severity]['cost'] += cost_impact
            summary['cost_analysis']['by_severity'][severity]['fte'] += fte_requirement
            
            # Add to type-based cost analysis
            if vuln_type not in summary['cost_analysis']['by_type']:
                summary['cost_analysis']['by_type'][vuln_type] = {'cost': 0, 'fte': 0}
            summary['cost_analysis']['by_type'][vuln_type]['cost'] += cost_impact
            summary['cost_analysis']['by_type'][vuln_type]['fte'] += fte_requirement
        
        # Calculate remediation timeline estimates
        summary['remediation_timeline']['critical_issues'] = summary['by_severity'].get('CRITICAL_BOMB', 0)
        summary['remediation_timeline']['high_priority'] = summary['by_severity'].get('HIGH_RISK', 0)
        summary['remediation_timeline']['medium_priority'] = summary['by_severity'].get('MEDIUM_RISK', 0)
        summary['remediation_timeline']['low_priority'] = summary['by_severity'].get('LOW_RISK', 0)
        
        return jsonify({
            'success': True,
            'summary': summary
        })
        
    except Exception as e:
        logger.error(f"Failed to get vulnerability summary: {e}")
        return jsonify({
            'success': False,
            'error': 'Internal server error',
            'error_code': 'METRICS_ERROR'
        }), 500

# ============================================================================
# Helper Functions
# ============================================================================

def _calculate_risk_score(vulnerability: dict) -> float:
    """Calculate risk score for a vulnerability"""
    try:
        base_score = 0
        
        # Severity scoring
        severity_scores = {
            'CRITICAL_BOMB': 100,
            'HIGH_RISK': 75,
            'MEDIUM_RISK': 50,
            'LOW_RISK': 25,
            'SUSPICIOUS': 30
        }
        base_score += severity_scores.get(vulnerability.get('severity'), 0)
        
        # Business impact scoring
        impact_scores = {
            'Critical': 25,
            'High': 20,
            'Medium': 15,
            'Low': 10
        }
        base_score += impact_scores.get(vulnerability.get('business_impact'), 0)
        
        # Exploitability scoring
        exploitability_scores = {
            'EASY': 20,
            'MEDIUM': 15,
            'HARD': 10,
            'VERY_HARD': 5
        }
        base_score += exploitability_scores.get(vulnerability.get('exploitability'), 0)
        
        # Normalize to 0-100 scale
        return min(100, max(0, base_score))
        
    except Exception:
        return 50.0

def _get_risk_level(risk_score: float) -> str:
    """Get risk level based on risk score"""
    if risk_score >= 80:
        return 'CRITICAL'
    elif risk_score >= 60:
        return 'HIGH'
    elif risk_score >= 40:
        return 'MEDIUM'
    else:
        return 'LOW'

def _calculate_remediation_priority(vulnerability: dict) -> str:
    """Calculate remediation priority for a vulnerability"""
    try:
        risk_score = _calculate_risk_score(vulnerability)
        
        if risk_score >= 80:
            return 'IMMEDIATE'
        elif risk_score >= 60:
            return 'HIGH'
        elif risk_score >= 40:
            return 'MEDIUM'
        else:
            return 'LOW'
            
    except Exception:
        return 'MEDIUM'

def _estimate_cost_impact(vulnerability: dict) -> float:
    """Estimate cost impact of a vulnerability"""
    try:
        base_cost = 0
        
        # Base cost by severity
        severity_costs = {
            'CRITICAL_BOMB': 10000,
            'HIGH_RISK': 5000,
            'MEDIUM_RISK': 2500,
            'LOW_RISK': 1000,
            'SUSPICIOUS': 1500
        }
        base_cost += severity_costs.get(vulnerability.get('severity'), 1000)
        
        # Additional cost by business impact
        impact_multipliers = {
            'Critical': 2.0,
            'High': 1.5,
            'Medium': 1.0,
            'Low': 0.5
        }
        multiplier = impact_multipliers.get(vulnerability.get('business_impact'), 1.0)
        
        return base_cost * multiplier
        
    except Exception:
        return 1000.0

def _estimate_fte_requirement(vulnerability: dict) -> float:
    """Estimate FTE requirement for remediation"""
    try:
        # Convert effort from minutes to hours
        effort_hours = vulnerability.get('effort', 0) / 60.0
        
        # Add complexity factor
        complexity_factors = {
            'CRITICAL_BOMB': 1.5,
            'HIGH_RISK': 1.3,
            'MEDIUM_RISK': 1.0,
            'LOW_RISK': 0.8,
            'SUSPICIOUS': 1.0
        }
        complexity = complexity_factors.get(vulnerability.get('severity'), 1.0)
        
        return effort_hours * complexity
        
    except Exception:
        return 1.0

def _get_remediation_history(vulnerability_id: str) -> list:
    """Get remediation history for a vulnerability"""
    try:
        # This would typically come from a remediation history table
        # For now, return empty list
        return []
    except Exception:
        return []

@vulnerability_api.route('/generate-terraform', methods=['POST'])
@rate_limit
@log_request
def generate_terraform():
    """Generate Terraform configuration for vulnerability remediation"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        vulnerability_id = data.get('vulnerability_id')
        ait_tag = data.get('ait_tag', 'AIT-Unknown')
        vulnerability_type = data.get('vulnerability_type', 'Unknown vulnerability')
        remediation_action = data.get('remediation_action', 'Update to latest version')
        
        # Generate Terraform configuration based on vulnerability type
        terraform_content = _generate_terraform_config(
            vulnerability_id, ait_tag, vulnerability_type, remediation_action
        )
        
        return jsonify({
            'success': True,
            'terraform_content': terraform_content,
            'vulnerability_id': vulnerability_id,
            'generated_at': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"Error generating Terraform: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def _generate_terraform_config(vulnerability_id: str, ait_tag: str, vulnerability_type: str, remediation_action: str) -> str:
    """Generate Terraform configuration for vulnerability remediation"""
    
    # Validate and sanitize inputs
    if not ait_tag or not isinstance(ait_tag, str):
        ait_tag = "AIT-Unknown"
    if not vulnerability_type or not isinstance(vulnerability_type, str):
        vulnerability_type = "Unknown vulnerability"
    if not remediation_action or not isinstance(remediation_action, str):
        remediation_action = "Update to latest version"
    
    # Sanitize ait_tag for use in resource names (remove special characters, convert to lowercase)
    ait_tag_safe = ait_tag.replace("-", "").replace("_", "").lower()
    
    # Base Terraform configuration template
    terraform_template = '''# Terraform Configuration for Vulnerability Remediation
# Generated for {ait_tag} - {vulnerability_type}
# Vulnerability ID: {vulnerability_id}
# Remediation Action: {remediation_action}
# Generated: {generated_time}

terraform {{
  required_version = ">= 1.0"
  required_providers {{
    aws = {{
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }}
  }}
}}

# Variables
variable "environment" {{
  description = "Environment name"
  type        = string
  default     = "production"
}}

variable "region" {{
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}}

# Provider configuration
provider "aws" {{
  region = var.region
  default_tags {{
    tags = {{
      Environment = var.environment
      AIT         = "{ait_tag}"
      Project     = "Vulnerability Remediation"
      ManagedBy   = "Terraform"
    }}
  }}
}}

# Security Groups
resource "aws_security_group" "remediation_sg" {{
  name_prefix = "remediation-{ait_tag_safe}-"
  description = "Security group for {ait_tag} vulnerability remediation"
  
  vpc_id = data.aws_vpc.default.id
  
  # Allow HTTPS
  ingress {{
    from_port   = 443
    to_port     = 443
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTPS access"
  }}
  
  # Allow HTTP (redirect to HTTPS)
  ingress {{
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "HTTP access (redirect to HTTPS)"
  }}
  
  # Allow SSH from specific IPs
  ingress {{
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["10.0.0.0/8"]
    description = "SSH access from internal network"
  }}
  
  egress {{
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
    description = "All outbound traffic"
  }}
  
  tags = {{
    Name = "remediation-security-group-{ait_tag_safe}"
  }}
}}

# Data sources
data "aws_vpc" "default" {{
  default = true
}}

data "aws_subnets" "default" {{
  filter {{
    name   = "vpc-id"
    values = [data.aws_vpc.default.id]
  }}
}}

# EC2 Instance for remediation
resource "aws_instance" "remediation_server" {{
  ami           = data.aws_ami.amazon_linux_2.id
  instance_type = "t3.medium"
  
  subnet_id                   = data.aws_subnets.default.ids[0]
  vpc_security_group_ids      = [aws_security_group.remediation_sg.id]
  associate_public_ip_address = true
  
  user_data = base64encode(templatefile("${{path.module}}/user_data.sh", {{
    ait_tag = "{ait_tag}"
    vulnerability_type = "{vulnerability_type}"
    remediation_action = "{remediation_action}"
  }}))
  
  root_block_device {{
    volume_size = 20
    volume_type = "gp3"
    encrypted   = true
  }}
  
  tags = {{
    Name = "remediation-server-{ait_tag_safe}"
  }}
}}

# AMI data source
data "aws_ami" "amazon_linux_2" {{
  most_recent = true
  owners      = ["amazon"]
  
  filter {{
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }}
  
  filter {{
    name   = "virtualization-type"
    values = ["hvm"]
  }}
}}

# CloudWatch Log Group
resource "aws_cloudwatch_log_group" "remediation_logs" {{
      name              = "/aws/ec2/remediation-{ait_tag_safe}"
  retention_in_days = 30
  
  tags = {{
    Name = "remediation-logs-{ait_tag_safe}"
  }}
}}

# CloudWatch Alarm for monitoring
resource "aws_cloudwatch_metric_alarm" "remediation_alarm" {{
      alarm_name          = "remediation-{ait_tag_safe}-alarm"
  comparison_operator = "GreaterThanThreshold"
  evaluation_periods  = "2"
  metric_name         = "CPUUtilization"
  namespace           = "AWS/EC2"
  period              = "300"
  statistic           = "Average"
  threshold           = "80"
  alarm_description   = "Monitor CPU utilization for remediation server"
  
  dimensions = {{
    InstanceId = aws_instance.remediation_server.id
  }}
}}

# Outputs
output "remediation_server_id" {{
  description = "ID of the remediation server"
  value       = aws_instance.remediation_server.id
}}

output "remediation_server_public_ip" {{
  description = "Public IP of the remediation server"
  value       = aws_instance.remediation_server.public_ip
}}

output "remediation_server_private_ip" {{
  description = "Private IP of the remediation server"
  value       = aws_instance.remediation_server.private_ip
}}

# User data script template
resource "local_file" "user_data_script" {{
  filename = "${{path.module}}/user_data.sh"
  content  = <<-EOF
#!/bin/bash
# User data script for {ait_tag} vulnerability remediation
# Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

# Update system
yum update -y

# Install required packages
yum install -y httpd php mysql

# Configure Apache with security headers
cat > /etc/httpd/conf.d/security.conf << 'APACHE_CONFIG'
# Security Headers
Header always set X-Content-Type-Options nosniff
Header always set X-Frame-Options DENY
Header always set X-XSS-Protection "1; mode=block"
Header always set Strict-Transport-Security "max-age=31536000; includeSubDomains"
Header always set Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline';"

# Disable server signature
ServerSignature Off
ServerTokens Prod

# Enable mod_rewrite
LoadModule rewrite_module modules/mod_rewrite.so

# Redirect HTTP to HTTPS
RewriteEngine On
RewriteCond %{{HTTPS}} off
RewriteRule ^(.*)$ https://%{{HTTP_HOST}}%{{REQUEST_URI}} [L,R=301]
APACHE_CONFIG

# Start and enable Apache
systemctl start httpd
systemctl enable httpd

# Configure firewall
firewall-cmd --permanent --add-service=http
firewall-cmd --permanent --add-service=https
firewall-cmd --reload

# Create monitoring script
cat > /opt/monitor.sh << 'MONITOR_SCRIPT'
#!/bin/bash
# Monitoring script for {ait_tag}

LOG_FILE="/var/log/remediation-monitor.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

echo "[$DATE] Starting monitoring for {ait_tag}" >> $LOG_FILE

# Check Apache status
if systemctl is-active --quiet httpd; then
    echo "[$DATE] Apache is running" >> $LOG_FILE
else
    echo "[$DATE] Apache is not running - attempting restart" >> $LOG_FILE
    systemctl restart httpd
fi

# Check disk usage
DISK_USAGE=$(df / | awk 'NR==2 {{print $5}}' | sed 's/%//')
if [ $DISK_USAGE -gt 80 ]; then
    echo "[$DATE] Warning: Disk usage is $DISK_USAGE%" >> $LOG_FILE
fi

# Check memory usage
MEM_USAGE=$(free | awk 'NR==2{{printf "%.0f", $3*100/$2}}')
if [ $MEM_USAGE -gt 80 ]; then
    echo "[$DATE] Warning: Memory usage is $MEM_USAGE%" >> $LOG_FILE
fi
MONITOR_SCRIPT

chmod +x /opt/monitor.sh

# Add monitoring to crontab
echo "*/5 * * * * /opt/monitor.sh" | crontab -

# Create backup script
cat > /opt/backup.sh << 'BACKUP_SCRIPT'
#!/bin/bash
# Backup script for {ait_tag}

BACKUP_DIR="/opt/backups"
DATE=$(date '+%Y%m%d_%H%M%S')

mkdir -p $BACKUP_DIR

# Backup Apache configuration
tar -czf $BACKUP_DIR/apache_config_$DATE.tar.gz /etc/httpd/

# Backup web content
tar -czf $BACKUP_DIR/web_content_$DATE.tar.gz /var/www/html/

echo "Backup completed: $BACKUP_DIR/*_$DATE.tar.gz"
BACKUP_SCRIPT

chmod +x /opt/backup.sh

# Log completion
echo "User data script completed for {ait_tag} at $(date)" > /var/log/user-data.log
EOF
}
'''
    
    # Use string replacement instead of format to avoid issues with unescaped braces
    terraform_content = terraform_template
    terraform_content = terraform_content.replace("{ait_tag}", ait_tag)
    terraform_content = terraform_content.replace("{ait_tag_safe}", ait_tag_safe)
    terraform_content = terraform_content.replace("{vulnerability_type}", vulnerability_type)
    terraform_content = terraform_content.replace("{vulnerability_id}", vulnerability_id)
    terraform_content = terraform_content.replace("{remediation_action}", remediation_action)
    terraform_content = terraform_content.replace("{generated_time}", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
    
    return terraform_content


# ============================================================================
# Application Vulnerability Folder Creation API
# ============================================================================

@vulnerability_api.route('/api/v1/vulnerabilities/create-application-folder', methods=['POST'])
def create_application_vulnerability_folder():
    """
    Create .github/vulnerability/application/ folder structure with remediation files
    """
    try:
        data = request.get_json()
        
        # Validate required fields
        required_fields = ['vulnerability_id', 'vulnerability_title', 'spk', 'repository', 'repo_url']
        for field in required_fields:
            if field not in data:
                return jsonify({
                    'success': False,
                    'error': f'Missing required field: {field}'
                }), 400
        
        vulnerability_id = data['vulnerability_id']
        vulnerability_title = data['vulnerability_title']
        spk = data['spk']
        repository = data['repository']
        repo_url = data['repo_url']
        ait_tag = data.get('ait_tag', 'AIT-Unknown')
        severity = data.get('severity', 'Unknown')
        remediation_action = data.get('remediation_action', 'Update to latest version')
        
        # Create the base directory path
        base_dir = Path(__file__).parent
        github_dir = base_dir / '.github' / 'vulnerability' / 'application'
        
        # Create directories if they don't exist
        github_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y-%m-%d')
        
        # Check if we should create unified file or multiple files
        create_unified = data.get('create_unified_file', False)
        comprehensive_prompt = data.get('comprehensive_prompt', '')
        
        if create_unified and comprehensive_prompt:
            # Create unified comprehensive remediation file
            main_remediation_content = comprehensive_prompt
        else:
            # Create main remediation file (legacy support)
            main_remediation_content = f"""# Comprehensive Security Remediation Prompt

## Context
This prompt is for GitHub Copilot to generate comprehensive remediation strategies for a security vulnerability identified in the application.

## Vulnerability Details
- **ID**: {vulnerability_id}
- **AIT Tag**: {ait_tag}
- **Title**: {vulnerability_title}
- **Severity**: {severity}
- **SPK**: {spk}
- **Repository**: {repository}
- **Repository URL**: {repo_url}
- **Generated Date**: {timestamp}

## Repository Information
- **Target Repository**: {repository}
- **Repository URL**: {repo_url}
- **SPK**: {spk}
- **AIT**: {ait_tag}

## Instructions for GitHub Copilot Agent

### 1. Repository Cloning and Analysis
1. **Clone the repository** from the provided URL: `{repo_url}`
2. **Scan all folders and files** in the repository
3. **Identify all instances** of the vulnerability type: {vulnerability_title}
4. **Create folder-wise analysis** for comprehensive remediation

### 2. Security Analysis Points to Cover

#### A. Content Security Policy (CSP) Issues
- **Wildcards in host lists**: Remove wildcards (*) from CSP directives
- **Unsafe-inline directives**: Replace with nonces or hashes
- **Unsafe-eval for script-src**: Remove unsafe-eval, use static code
- **Missing CSP headers**: Add proper CSP headers to all HTTP responses

#### B. Inline Style and Script Issues
- **Inline styles**: Move all inline styles to external CSS files
- **Inline JavaScript**: Move all inline JavaScript to external JS files
- **Event handlers**: Replace onclick/onload with jQuery event handlers
- **Multiple class attributes**: Combine multiple class attributes into single attribute

#### C. JavaScript Security Issues
- **Eval statements**: Replace eval() with static code alternatives
- **Unsafe src events**: Move onclick/onload to jQuery event handlers
- **Global CSS modifications**: Use specific CSS properties with !important
- **CSS overrides**: Apply CSS to IDs when class overrides fail

#### D. HTML Security Issues
- **Unsafe HTML attributes**: Sanitize all user inputs
- **Missing input validation**: Add comprehensive input validation
- **XSS vulnerabilities**: Implement proper output encoding
- **SQL injection**: Use parameterized queries

### 3. Folder-wise Remediation Strategy

#### Create separate prompts for each folder:
1. **Frontend/UI folders**: Focus on CSP, inline styles, and JavaScript security
2. **Backend/API folders**: Focus on input validation, SQL injection, and authentication
3. **Configuration folders**: Focus on security headers and environment variables
4. **Database folders**: Focus on SQL injection and data validation
5. **Authentication folders**: Focus on session management and credential handling

### 4. File Structure for .github Folder
Create the following structure in the .github folder:
```
.github/
├── vulnerability/
│   ├── application/
│   │   ├── {vulnerability_id}_remediation.md
│   │   ├── frontend_remediation.md
│   │   ├── backend_remediation.md
│   │   ├── database_remediation.md
│   │   └── configuration_remediation.md
│   └── README.md
```

### 5. Comprehensive Remediation Checklist

#### Frontend Security:
- [ ] Remove all inline styles and move to external CSS
- [ ] Remove all inline JavaScript and move to external JS
- [ ] Implement proper CSP headers
- [ ] Replace onclick/onload with jQuery event handlers
- [ ] Sanitize all user inputs
- [ ] Implement proper output encoding

#### Backend Security:
- [ ] Add input validation for all endpoints
- [ ] Use parameterized queries for database operations
- [ ] Implement proper authentication and authorization
- [ ] Add rate limiting and request validation
- [ ] Implement secure session management

#### Database Security:
- [ ] Use parameterized queries
- [ ] Implement proper data validation
- [ ] Add database access controls
- [ ] Implement audit logging

#### Configuration Security:
- [ ] Remove hardcoded credentials
- [ ] Use environment variables for sensitive data
- [ ] Implement proper security headers
- [ ] Configure HTTPS and SSL/TLS properly

### 6. Expected Output
Generate comprehensive remediation files for each folder containing:
1. **Detailed analysis** of security issues found
2. **Step-by-step remediation instructions**
3. **Code examples** showing before and after
4. **Testing procedures** to verify fixes
5. **Documentation** for future maintenance

### 7. Important Notes
- **Save all prompts** in the .github/vulnerability/application/ folder
- **Use the exact vulnerability ID** for naming the main remediation file
- **Ensure comprehensive coverage** of all security aspects
- **Include testing procedures** for each remediation
- **Document all changes** for audit purposes

Please generate the comprehensive remediation strategy now and save it to the specified .github folder structure.
"""

        # Create frontend remediation file
        frontend_remediation_content = f"""# Frontend Remediation Guide

## Vulnerability: {vulnerability_title}
## ID: {vulnerability_id}
## Generated: {timestamp}

## Frontend Security Issues to Address

### 1. Content Security Policy (CSP)
- Remove wildcards (*) from CSP directives
- Replace unsafe-inline with nonces or hashes
- Remove unsafe-eval from script-src
- Add proper CSP headers to all HTTP responses

### 2. Inline Styles and Scripts
- Move all inline styles to external CSS files
- Move all inline JavaScript to external JS files
- Replace onclick/onload with proper event handlers
- Combine multiple class attributes

### 3. JavaScript Security
- Replace eval() with static code alternatives
- Move onclick/onload to jQuery event handlers
- Use specific CSS properties with !important
- Apply CSS to IDs when class overrides fail

## Implementation Steps
1. Audit all HTML files for inline styles and scripts
2. Create external CSS and JS files
3. Update HTML to reference external files
4. Implement proper CSP headers
5. Test all functionality after changes

## Testing Checklist
- [ ] All inline styles moved to external CSS
- [ ] All inline scripts moved to external JS
- [ ] CSP headers properly configured
- [ ] No console errors after changes
- [ ] All functionality working as expected
"""

        # Create backend remediation file
        backend_remediation_content = f"""# Backend Remediation Guide

## Vulnerability: {vulnerability_title}
## ID: {vulnerability_id}
## Generated: {timestamp}

## Backend Security Issues to Address

### 1. Input Validation
- Add comprehensive input validation for all endpoints
- Sanitize all user inputs
- Implement proper data type validation
- Add length and format validation

### 2. SQL Injection Prevention
- Use parameterized queries for all database operations
- Implement proper ORM usage
- Add database access controls
- Implement audit logging

### 3. Authentication and Authorization
- Implement proper session management
- Add rate limiting and request validation
- Use secure password hashing
- Implement proper logout functionality

## Implementation Steps
1. Review all API endpoints for security issues
2. Add input validation middleware
3. Update database queries to use parameters
4. Implement proper authentication
5. Add security headers

## Testing Checklist
- [ ] All inputs properly validated
- [ ] No SQL injection vulnerabilities
- [ ] Proper authentication implemented
- [ ] Security headers added
- [ ] Rate limiting implemented
"""

        # Create database remediation file
        database_remediation_content = f"""# Database Remediation Guide

## Vulnerability: {vulnerability_title}
## ID: {vulnerability_id}
## Generated: {timestamp}

## Database Security Issues to Address

### 1. SQL Injection Prevention
- Use parameterized queries
- Implement proper ORM usage
- Add database access controls
- Implement audit logging

### 2. Data Validation
- Implement proper data validation
- Add database constraints
- Use proper data types
- Implement data encryption

### 3. Access Control
- Implement proper user permissions
- Add database user management
- Use connection pooling
- Implement backup strategies

## Implementation Steps
1. Review all database queries
2. Update queries to use parameters
3. Add proper constraints
4. Implement access controls
5. Set up monitoring

## Testing Checklist
- [ ] All queries use parameters
- [ ] Proper constraints in place
- [ ] Access controls implemented
- [ ] Monitoring set up
- [ ] Backup strategy in place
"""

        # Create configuration remediation file
        configuration_remediation_content = f"""# Configuration Remediation Guide

## Vulnerability: {vulnerability_title}
## ID: {vulnerability_id}
## Generated: {timestamp}

## Configuration Security Issues to Address

### 1. Environment Variables
- Remove hardcoded credentials
- Use environment variables for sensitive data
- Implement proper secret management
- Add configuration validation

### 2. Security Headers
- Implement proper security headers
- Configure HTTPS and SSL/TLS properly
- Add CORS configuration
- Implement security middleware

### 3. Server Configuration
- Update server security settings
- Configure proper logging
- Implement monitoring
- Add health checks

## Implementation Steps
1. Review all configuration files
2. Move secrets to environment variables
3. Add security headers
4. Configure HTTPS properly
5. Set up monitoring

## Testing Checklist
- [ ] No hardcoded credentials
- [ ] Proper environment variables
- [ ] Security headers configured
- [ ] HTTPS properly configured
- [ ] Monitoring in place
"""

        # Create README file
        readme_content = f"""# Vulnerability Remediation

This folder contains comprehensive remediation guides for security vulnerabilities identified in the application.

## Structure
- `application/` - Application-level vulnerability remediations
- `infrastructure/` - Infrastructure-level vulnerability remediations

## Usage
1. Navigate to the appropriate subfolder
2. Review the remediation guides
3. Follow the implementation steps
4. Complete the testing checklist

## Generated: {timestamp}
## Vulnerability ID: {vulnerability_id}
"""

        # Clean up old multiple files if creating unified file
        if create_unified and comprehensive_prompt:
            # Remove old multiple files to avoid confusion
            old_files = [
                github_dir / f"{vulnerability_id}_remediation.md",
                github_dir / "frontend_remediation.md",
                github_dir / "backend_remediation.md", 
                github_dir / "database_remediation.md",
                github_dir / "configuration_remediation.md"
            ]
            
            for old_file in old_files:
                if old_file.exists():
                    try:
                        old_file.unlink()
                        logger.info(f"Removed old file: {old_file}")
                    except Exception as e:
                        logger.warning(f"Could not remove old file {old_file}: {e}")

        # Write files based on unified flag
        files_created = []
        
        if create_unified and comprehensive_prompt:
            # Create in-place remediation structure
            # Create main comprehensive prompt file (THIS IS THE ONE TO USE WITH GITHUB COPILOT)
            unified_file = github_dir / f"{vulnerability_id}_GITHUB_COPILOT_PROMPT.md"
            with open(unified_file, 'w', encoding='utf-8') as f:
                f.write(main_remediation_content)
            files_created.append(str(unified_file.relative_to(base_dir)))
            
            # Create README file
            readme_file = base_dir / '.github' / 'vulnerability' / 'README.md'
            readme_file.parent.mkdir(parents=True, exist_ok=True)
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            files_created.append(str(readme_file.relative_to(base_dir)))
            
            logger.info(f"Created in-place remediation structure for {vulnerability_id}")
        else:
            # Legacy: Create multiple files
            # Main remediation file
            main_file = github_dir / f"{vulnerability_id}_remediation.md"
            with open(main_file, 'w', encoding='utf-8') as f:
                f.write(main_remediation_content)
            files_created.append(str(main_file.relative_to(base_dir)))
            
            # Frontend remediation file
            frontend_file = github_dir / "frontend_remediation.md"
            with open(frontend_file, 'w', encoding='utf-8') as f:
                f.write(frontend_remediation_content)
            files_created.append(str(frontend_file.relative_to(base_dir)))
            
            # Backend remediation file
            backend_file = github_dir / "backend_remediation.md"
            with open(backend_file, 'w', encoding='utf-8') as f:
                f.write(backend_remediation_content)
            files_created.append(str(backend_file.relative_to(base_dir)))
            
            # Database remediation file
            database_file = github_dir / "database_remediation.md"
            with open(database_file, 'w', encoding='utf-8') as f:
                f.write(database_remediation_content)
            files_created.append(str(database_file.relative_to(base_dir)))
            
            # Configuration remediation file
            config_file = github_dir / "configuration_remediation.md"
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(configuration_remediation_content)
            files_created.append(str(config_file.relative_to(base_dir)))
            
            # README file
            readme_file = base_dir / '.github' / 'vulnerability' / 'README.md'
            readme_file.parent.mkdir(parents=True, exist_ok=True)
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            files_created.append(str(readme_file.relative_to(base_dir)))
            
            logger.info(f"Created multiple remediation files for {vulnerability_id}")
        
        logger.info(f"Created application vulnerability folder structure for {vulnerability_id}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully created .github/vulnerability/application/ folder structure for vulnerability {vulnerability_id}',
            'files_created': files_created,
            'folder_path': str(github_dir.relative_to(base_dir)),
            'vulnerability_id': vulnerability_id
        })
        
    except Exception as e:
        logger.error(f"Error creating application vulnerability folder: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to create folder structure: {str(e)}'
        }), 500


@vulnerability_api.route('/api/v1/vulnerabilities/cleanup-application-files', methods=['POST'])
def cleanup_application_files():
    """
    Clean up old multiple application vulnerability files and keep only unified files
    """
    try:
        data = request.get_json()
        vulnerability_id = data.get('vulnerability_id')
        
        # Create the base directory path
        base_dir = Path(__file__).parent
        github_dir = base_dir / '.github' / 'vulnerability' / 'application'
        
        if not github_dir.exists():
            return jsonify({
                'success': True,
                'message': 'No application vulnerability folder found',
                'files_removed': []
            })
        
        files_removed = []
        
        if vulnerability_id:
            # Clean up specific vulnerability files
            old_files = [
                github_dir / f"{vulnerability_id}_remediation.md",
                github_dir / "frontend_remediation.md",
                github_dir / "backend_remediation.md", 
                github_dir / "database_remediation.md",
                github_dir / "configuration_remediation.md"
            ]
        else:
            # Clean up all old multiple files (general cleanup)
            old_files = [
                github_dir / "frontend_remediation.md",
                github_dir / "backend_remediation.md", 
                github_dir / "database_remediation.md",
                github_dir / "configuration_remediation.md"
            ]
            
            # Also clean up any old _remediation.md files that don't have _comprehensive_ in the name
            for file in github_dir.glob("*_remediation.md"):
                if "_comprehensive_" not in file.name:
                    old_files.append(file)
        
        for old_file in old_files:
            if old_file.exists():
                try:
                    old_file.unlink()
                    files_removed.append(str(old_file.relative_to(base_dir)))
                    logger.info(f"Removed old file: {old_file}")
                except Exception as e:
                    logger.warning(f"Could not remove old file {old_file}: {e}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully cleaned up {len(files_removed)} old files',
            'files_removed': files_removed
        })
        
    except Exception as e:
        logger.error(f"Error cleaning up application files: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to cleanup files: {str(e)}'
        }), 500


@vulnerability_api.route('/api/v1/vulnerabilities/create-infrastructure-prompt', methods=['POST'])
def create_infrastructure_prompt():
    """
    Create infrastructure Terraform prompt file in .github/vulnerability/infrastructure/ folder
    """
    try:
        data = request.get_json()
        
        # Validate required fields
        required_fields = ['vulnerability_id', 'vulnerability_title', 'terraform_prompt']
        for field in required_fields:
            if field not in data:
                return jsonify({
                    'success': False,
                    'error': f'Missing required field: {field}'
                }), 400
        
        vulnerability_id = data['vulnerability_id']
        vulnerability_title = data['vulnerability_title']
        terraform_prompt = data['terraform_prompt']
        ait_tag = data.get('ait_tag', 'AIT-Unknown')
        severity = data.get('severity', 'Unknown')
        remediation_action = data.get('remediation_action', 'Update to latest version')
        
        # Create the base directory path
        base_dir = Path(__file__).parent
        infrastructure_dir = base_dir / '.github' / 'vulnerability' / 'infrastructure'
        
        # Create directories if they don't exist
        infrastructure_dir.mkdir(parents=True, exist_ok=True)
        
        # Create the prompt file
        prompt_filename = f"{vulnerability_id}_infrastructure_prompt.md"
        prompt_file = infrastructure_dir / prompt_filename
        
        with open(prompt_file, 'w', encoding='utf-8') as f:
            f.write(terraform_prompt)
        
        logger.info(f"Created infrastructure prompt file for {vulnerability_id}")
        
        return jsonify({
            'success': True,
            'message': f'Successfully created infrastructure prompt file for vulnerability {vulnerability_id}',
            'file_path': str(prompt_file.relative_to(base_dir)),
            'vulnerability_id': vulnerability_id,
            'terraform_prompt': terraform_prompt
        })
        
    except Exception as e:
        logger.error(f"Error creating infrastructure prompt file: {e}")
        return jsonify({
            'success': False,
            'error': f'Failed to create prompt file: {str(e)}'
        }), 500


