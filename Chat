def upload(self, results, externalRunID, applicationModuleID, testSuiteID):
    """
    Upload test results to Octane.
    """
    sliceSize = self.octaneConfig.get("uploadSliceSize")
    slice = 0
    max_retries = 5
    running_tasks = []  # To store running tasks temporarily

    while True:
        resultsSlice = results[slice*sliceSize: (slice+1)*sliceSize]
        if resultsSlice:
            # Prepare XML test results
            testRuns = "\n".join(
                TEST_RUN.format(
                    testname=testname.split('.')[-1].rsplit('.', 3)[1] + '.' + testname.rsplit('.', 1)[-1],
                    testclass=testclass,
                    status=status,
                    started=started,
                    duration=int(duration),
                    package=testname.split('.')[-1].rsplit('.', 3)[0],
                    module=testname.split('.')[-1].rsplit('.', 3)[0]
                ) for (testname, testclass, status, started, duration) in resultsSlice
            )

            data = EVIDENCE_TEMPLATE_TEST_SUITE.format(
                test_results=testRuns,
                testSuiteID=testSuiteID,
                externalRunID=externalRunID,
                applicationModuleID=applicationModuleID
            )

            # Upload results
            response = self.endpoint.post("test-results", data=data, dataType="xml")
            status, task_response = response
            task_id = task_response.get("id")

            if status != "Success":
                logger.error(f"Upload failed for results slice: {response}")
                raise RuntimeError(f"Failed to upload test results slice: {response}")

            # Retry mechanism to check task status
            retry_count = 0
            while retry_count <= max_retries:
                _, task_status_resp = self.endpoint.get(f"test-results/{task_id}")
                task_status = task_status_resp.get("status")

                if task_status == "SUCCESS":
                    logger.info(f"Upload task {task_id} completed successfully.")
                    break
                elif task_status in ["FAILED", "ERROR"]:
                    logger.error(f"Upload task {task_id} failed: {task_status_resp.get('errorDetails')}")
                    raise RuntimeError(f"Upload task {task_id} failed.")
                elif task_status == "RUNNING":
                    if retry_count == max_retries:
                        logger.warning(f"Task {task_id} still RUNNING after {max_retries} retries. Storing for later tracking.")
                        running_tasks.append(task_id)
                        break

                    else:
                        logger.info(f"Task {task_id} still RUNNING. Retrying {retry_count + 1}/{max_retries}...")
                        retry_count += 1
                        time.sleep(5)
                else:
                    logger.warning(f"Unexpected task status {task_status} for task {task_id}. Moving on.")
                    break

            slice += 1
        else:
            break

    return running_tasks  # Important: Return the list of running task

def track_pending_tasks(self, running_tasks):
    """
    Track all pending tasks and ensure they are completed successfully.
    """
    for task_id in running_tasks:
        logger.info(f"Checking final status of pending task {task_id}")
        _, task_status_resp = self.octaneClient.endpoint.get(f"test-results/{task_id}")
        task_status = task_status_resp.get("status")

        if task_status != "SUCCESS":
            logger.error(f"Pending task {task_id} not completed successfully: {task_status}")
            raise RuntimeError(f"Pending task {task_id} failed or incomplete, cannot proceed with backlog coverage update.")
        else:
            logger.info(f"Pending task {task_id} completed successfully.")
